% ============================================================================
% NL-SRE-Semantico: Motor de Desambiguación Semántica para Español
% Paper para: Procesamiento del Lenguaje Natural (SEPLN)
% Autor: Francisco Molina-Burgos
% Fecha: Enero 2026
% ============================================================================
% NOTA: Para revisión ciega, eliminar \author y \affiliation antes de enviar
% ============================================================================

\documentclass[11pt,a4paper]{article}

% Paquetes necesarios
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[spanish,english]{babel}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{geometry}

\geometry{margin=2.5cm}

% Configuración de listings para Rust
\lstdefinelanguage{Rust}{
  keywords={fn, let, mut, pub, struct, impl, enum, match, if, else, for, while, loop, return, use, mod, self, Self, true, false, Some, None, Ok, Err},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={String, Vec, HashMap, Option, Result, f64, usize, bool},
  ndkeywordstyle=\color{purple},
  identifierstyle=\color{black},
  sensitive=true,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{gray}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]",
}
\lstset{
  language=Rust,
  basicstyle=\ttfamily\footnotesize,
  breaklines=true,
  frame=single,
  numbers=left,
  numberstyle=\tiny\color{gray},
}

% ============================================================================
\title{NL-SRE-Semantico: Motor de Desambiguación Semántica Probabilística\\
para Español Basado en Arquitectura Híbrida UNIFORM-TAO-APPLOG}

% PARA REVISIÓN CIEGA: Comentar las siguientes líneas
\author{Francisco Molina-Burgos$^{1}$}
\date{}

% ============================================================================
\begin{document}

\maketitle

% Afiliación (comentar para revisión ciega)
\begin{center}
$^{1}$Avermex Research Division, Mérida, Yucatán, México\\
\texttt{fmolina@avermex.com}
\end{center}

\vspace{0.5cm}

% ============================================================================
% RESUMEN EN ESPAÑOL
% ============================================================================
\selectlanguage{spanish}

\begin{abstract}
\textbf{Resumen:} Presentamos NL-SRE-Semantico, un motor de desambiguación semántica probabilística para español implementado en Rust puro sin dependencias externas. El sistema emplea una arquitectura novedosa de cuatro capas inspirada en paradigmas clásicos de la inteligencia artificial simbólica: UNIFORM (1981) para unificación universal, TAO (1983) para paso de mensajes orientado a objetos, y APPLOG (1984) para variables compartidas entre paradigmas lógico y funcional. A diferencia de los enfoques basados en redes neuronales, nuestro sistema es completamente determinista, explicable, y produce resultados reproducibles. La fórmula de puntuación combina similitud de caracteres ($\alpha$), validación gramatical ($\beta$), y contexto semántico ($\gamma$) con pesos configurables. Evaluamos el sistema con un diccionario de 218,000 palabras del español (RAE + variantes latinoamericanas) y demostramos que el contexto semántico puede invertir decisiones basadas únicamente en distancia de edición. El código fuente está disponible bajo licencia MIT con DOI Zenodo asignado.

\textbf{Palabras clave:} desambiguación semántica, procesamiento del lenguaje natural, español, Rust, sistemas simbólicos.
\end{abstract}

% ============================================================================
% ABSTRACT EN INGLÉS
% ============================================================================
\selectlanguage{english}

\begin{abstract}
\textbf{Abstract:} We present NL-SRE-Semantico, a probabilistic semantic disambiguation engine for Spanish implemented in pure Rust with zero external dependencies. The system employs a novel four-layer architecture inspired by classic symbolic AI paradigms: UNIFORM (1981) for universal unification, TAO (1983) for object-oriented message passing, and APPLOG (1984) for shared variables between logic and functional paradigms. Unlike neural network approaches, our system is fully deterministic, explainable, and produces reproducible results. The scoring formula combines character similarity ($\alpha$), grammatical validation ($\beta$), and semantic context ($\gamma$) with configurable weights. We evaluate the system with a dictionary of 218,000 Spanish words (RAE + Latin American variants) and demonstrate that semantic context can reverse decisions based solely on edit distance. Source code is available under MIT license with assigned Zenodo DOI.

\textbf{Keywords:} semantic disambiguation, natural language processing, Spanish, Rust, symbolic systems.
\end{abstract}

\selectlanguage{spanish}

% ============================================================================
\section{Introducción}
% ============================================================================

La desambiguación semántica es un problema fundamental en el procesamiento del lenguaje natural (PLN). Dado un texto con palabras ambiguas o erróneas, el sistema debe seleccionar la interpretación correcta considerando el contexto lingüístico y semántico.

Los enfoques modernos basados en modelos de lenguaje grandes (LLMs) han demostrado capacidades impresionantes, pero presentan limitaciones significativas: (1) son no deterministas, produciendo diferentes salidas para la misma entrada; (2) carecen de explicabilidad, funcionando como ``cajas negras''; (3) requieren recursos computacionales sustanciales; y (4) pueden ``alucinar'' información incorrecta.

Proponemos un enfoque alternativo basado en sistemas simbólicos clásicos, específicamente inspirado en tres paradigmas de los años 80:

\begin{itemize}
    \item \textbf{UNIFORM} \citep{warren1981}: Kernel de unificación universal donde todas las operaciones de matching pasan por un único punto optimizado.
    \item \textbf{TAO} \citep{takeuchi1983}: Sistema de paso de mensajes con encapsulamiento orientado a objetos, inspirado en Smalltalk.
    \item \textbf{APPLOG} \citep{robinson1984}: Integración de variables compartidas entre programación lógica (Prolog) y funcional (LISP).
\end{itemize}

Nuestra contribución principal es demostrar que estos paradigmas clásicos, implementados en un lenguaje moderno (Rust), pueden producir un sistema de desambiguación competitivo que es completamente determinista, explicable, y eficiente.

% ============================================================================
\section{Trabajos Relacionados}
% ============================================================================

\subsection{Desambiguación Léxica para Español}

El español presenta desafíos específicos para la desambiguación debido a su flexibilidad en el orden de palabras (SVO, OVS, VSO), rica morfología verbal, y variación dialectal significativa entre regiones.

Trabajos previos han abordado la desambiguación del español usando métodos estadísticos \citep{agirre2006}, aprendizaje supervisado \citep{navigli2009}, y más recientemente, modelos de lenguaje preentrenados como BETO \citep{canete2020}.

\subsection{Sistemas Simbólicos en PLN}

Los sistemas simbólicos dominaron el PLN hasta los años 90. El resurgimiento del interés en sistemas híbridos neuro-simbólicos \citep{garcez2019} sugiere que los enfoques puramente simbólicos aún tienen valor, especialmente para aplicaciones que requieren explicabilidad y determinismo.

% ============================================================================
\section{Arquitectura del Sistema}
% ============================================================================

NL-SRE-Semantico emplea una arquitectura de cuatro capas (Figura \ref{fig:arquitectura}):

\begin{figure}[h]
\centering
\begin{verbatim}
┌─────────────────────────────────────────────────────┐
│ CAPA 4: UNIFORM Kernel                              │
│ → Unificación universal como meta-operador          │
├─────────────────────────────────────────────────────┤
│ CAPA 3: TAO Layer                                   │
│ → Encapsulamiento + message-passing                 │
├─────────────────────────────────────────────────────┤
│ CAPA 2: APPLOG Layer                                │
│ → Variables compartidas + validación de constraints │
├─────────────────────────────────────────────────────┤
│ CAPA 1: Motores Base                                │
│ → CharMatcher, SpanishGrammar, SemanticDB          │
└─────────────────────────────────────────────────────┘
\end{verbatim}
\caption{Arquitectura de cuatro capas de NL-SRE-Semantico}
\label{fig:arquitectura}
\end{figure}

\subsection{Capa 1: Motores Base}

La capa base contiene tres componentes especializados:

\textbf{CharMatcher:} Implementa un algoritmo de distancia de edición ponderada (Damerau-Levenshtein modificado) que considera la proximidad de teclas en el teclado QWERTY español. Dado un token desconocido, genera candidatos ordenados por similitud de caracteres.

\textbf{SpanishGrammar:} Motor de gramática española que valida estructuras sintácticas considerando la flexibilidad del orden de palabras. Soporta patrones SVO, OVS, VSO, y SV, reconociendo que oraciones como ``Me gusta la casa azul'' y ``La casa azul me gusta'' son igualmente válidas.

\textbf{SemanticDB:} Base de datos semántica con categorización de palabras (Lugar, Persona, Objeto, Emoción, Concepto) y reglas de compatibilidad temática. Permite inferir temas del contexto y evaluar compatibilidad de candidatos.

\subsection{Capa 2: APPLOG Layer}

La capa APPLOG mantiene un contexto compartido entre todos los componentes:

\begin{lstlisting}
pub struct SharedContext {
    bindings: HashMap<String, UnifyValue>,
    constraints: Vec<Constraint>,
    sources: HashMap<String, Source>,
    confidence: HashMap<String, f64>,
}
\end{lstlisting}

Cada binding incluye su fuente (CharMatcher, Grammar, Semantic) y nivel de confianza, permitiendo resolución de conflictos informada.

\subsection{Capa 3: TAO Layer}

La capa TAO implementa comunicación por mensajes entre componentes gramaticales:

\begin{lstlisting}
pub enum GrammaticalRole {
    Subject, DirectObject, IndirectObject,
    Complement, Modifier, Determiner
}

pub struct GrammaticalComponent {
    role: GrammaticalRole,
    content: String,
    properties: HashMap<String, String>,
}
\end{lstlisting}

Los componentes se comunican mediante paso de mensajes, permitiendo análisis incremental de estructuras oracionales.

\subsection{Capa 4: UNIFORM Kernel}

El kernel UNIFORM proporciona unificación universal para todas las operaciones de matching:

\begin{lstlisting}
pub fn unify(&mut self, a: &UnifyValue, b: &UnifyValue) -> bool {
    let a = self.deref(a);
    let b = self.deref(b);

    match (&a, &b) {
        (Var(va), Var(vb)) if va == vb => true,
        (Var(va), _) => self.bind(va, b),
        (_, Var(vb)) => self.bind(vb, a),
        (Atom(aa), Atom(ab)) => aa == ab,
        (Num(na), Num(nb)) => (na - nb).abs() < 1e-10,
        (List(la), List(lb)) => self.unify_lists(la, lb),
        (Struct(fa, argsa), Struct(fb, argsb)) =>
            fa == fb && self.unify_lists(argsa, argsb),
        _ => false,
    }
}
\end{lstlisting}

El kernel incluye occurs-check para prevenir ciclos infinitos y soporta backtracking mediante checkpoints.

% ============================================================================
\section{Algoritmo de Desambiguación}
% ============================================================================

\subsection{Fórmula de Puntuación}

El score final para cada candidato $c$ dado un contexto $ctx$ se calcula como:

\begin{equation}
\text{Score}(c, ctx) = \alpha \cdot S_{char}(c) + \beta \cdot S_{gram}(c, ctx) + \gamma \cdot S_{sem}(c, ctx)
\label{eq:score}
\end{equation}

donde:
\begin{itemize}
    \item $S_{char}(c) \in [0,1]$: Similitud de caracteres entre el token original y el candidato
    \item $S_{gram}(c, ctx) \in [0,1]$: Validez gramatical del candidato en la posición dada
    \item $S_{sem}(c, ctx) \in [0,1]$: Compatibilidad semántica con el tema inferido
    \item $\alpha + \beta + \gamma = 1$: Pesos configurables (default: 0.30, 0.30, 0.40)
\end{itemize}

\subsection{Proceso de Desambiguación}

El Algoritmo \ref{alg:disambiguate} describe el proceso completo:

\begin{algorithm}[h]
\caption{Desambiguación Semántica}
\label{alg:disambiguate}
\begin{algorithmic}[1]
\Require Oración $S$, Configuración $(\alpha, \beta, \gamma)$
\Ensure Oración corregida $S'$, Explicaciones $E$

\State $tokens \gets \text{Tokenize}(S)$
\State $anomalies \gets \{(i, t) : t \in tokens \land t \notin \text{Dictionary}\}$
\If{$anomalies = \emptyset$}
    \State \Return $(S, \emptyset)$
\EndIf

\State $context \gets \{t \in tokens : t \in \text{Dictionary}\}$
\State $theme \gets \text{InferTheme}(context)$

\ForAll{$(i, word) \in anomalies$}
    \State $candidates \gets \text{FindCandidates}(word)$
    \ForAll{$c \in candidates$}
        \State $s_c \gets \alpha \cdot S_{char}(c) + \beta \cdot S_{gram}(c, i, tokens) + \gamma \cdot S_{sem}(c, theme)$
    \EndFor
    \State $best \gets \arg\max_c s_c$
    \State $tokens[i] \gets best$
    \State $E[i] \gets \text{GenerateExplanation}(word, best, candidates)$
\EndFor

\State \Return $(\text{Join}(tokens), E)$
\end{algorithmic}
\end{algorithm}

% ============================================================================
\section{Evaluación Experimental}
% ============================================================================

\subsection{Datos}

El sistema utiliza un diccionario combinado de:
\begin{itemize}
    \item Diccionario RAE: 93,000 lemas
    \item Variantes latinoamericanas: 125,000 entradas adicionales
    \item Total: 218,000 palabras únicas con frecuencias de uso
\end{itemize}

\subsection{Casos de Estudio}

Evaluamos la capacidad del sistema para resolver ambigüedades donde el contexto semántico invierte la decisión basada en caracteres.

\textbf{Caso 1: ``smor'' en contexto arquitectónico}

\begin{table}[h]
\centering
\caption{Desambiguación de ``smor'' según contexto}
\label{tab:smor}
\begin{tabular}{llccc}
\toprule
\textbf{Contexto} & \textbf{Resultado} & $S_{char}$ & $S_{gram}$ & $S_{sem}$ \\
\midrule
``Visité el Coliseo romano en smor'' & roma & 0.50 & 0.90 & 0.98 \\
``Te quiero con todo mi smor'' & amor & 0.50 & 0.85 & 0.95 \\
``Viajé a smor en avión'' & roma & 0.50 & 0.90 & 0.80 \\
\bottomrule
\end{tabular}
\end{table}

Aunque ``amor'' y ``roma'' tienen idéntica distancia de caracteres a ``smor'' (son anagramas), el contexto semántico determina la selección correcta.

\textbf{Caso 2: Flexibilidad gramatical del español}

\begin{table}[h]
\centering
\caption{Validación gramatical de ordenamientos}
\label{tab:grammar}
\begin{tabular}{lcc}
\toprule
\textbf{Oración} & \textbf{Patrón} & $S_{gram}$ \\
\midrule
``Juan come manzanas'' & SVO & 1.00 \\
``Manzanas come Juan'' & OVS & 1.00 \\
``Come Juan manzanas'' & VSO & 1.00 \\
``Me gusta la casa azul'' & OVS & 1.00 \\
``La casa azul me gusta'' & SVO & 1.00 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Rendimiento}

\begin{table}[h]
\centering
\caption{Métricas de rendimiento}
\label{tab:performance}
\begin{tabular}{lr}
\toprule
\textbf{Métrica} & \textbf{Valor} \\
\midrule
Tiempo de carga del diccionario & 45 ms \\
Tiempo promedio por oración (10 tokens) & 0.8 ms \\
Uso de memoria (diccionario cargado) & 12 MB \\
Tamaño del binario (release) & 1.2 MB \\
Tests pasando & 31/31 \\
\bottomrule
\end{tabular}
\end{table}

% ============================================================================
\section{Implementación}
% ============================================================================

El sistema está implementado en Rust 1.75+ con las siguientes características:

\begin{itemize}
    \item \textbf{Zero dependencias externas}: Todo el código es Rust puro
    \item \textbf{Determinismo}: Mismo input produce siempre mismo output
    \item \textbf{Explicabilidad}: Cada decisión incluye justificación detallada
    \item \textbf{Configurabilidad}: Pesos $(\alpha, \beta, \gamma)$ ajustables
\end{itemize}

El código fuente está disponible en GitHub bajo licencia MIT:
\begin{itemize}
    \item Repositorio: \url{https://github.com/Yatrogenesis/NL-SRE-Semantico}
    \item DOI: 10.5281/zenodo.18293530
\end{itemize}

% ============================================================================
\section{Conclusiones y Trabajo Futuro}
% ============================================================================

Hemos presentado NL-SRE-Semantico, un motor de desambiguación semántica que demuestra la viabilidad de sistemas simbólicos clásicos implementados en lenguajes modernos. Las principales contribuciones son:

\begin{enumerate}
    \item Arquitectura de cuatro capas basada en UNIFORM, TAO, y APPLOG
    \item Fórmula de puntuación explícita y configurable
    \item Implementación eficiente en Rust puro sin dependencias
    \item Soporte para la flexibilidad gramatical del español
\end{enumerate}

El trabajo futuro incluye: (1) expansión del diccionario con más variantes dialectales; (2) integración con sistemas de reconocimiento de voz; (3) optimizaciones SIMD para el kernel UNIFORM; y (4) evaluación comparativa formal con sistemas basados en LLMs.

% ============================================================================
% AGRADECIMIENTOS
% ============================================================================
\section*{Agradecimientos}

Este trabajo fue desarrollado en Avermex Research Division. El autor agradece a la comunidad de Rust por las herramientas de desarrollo.

% ============================================================================
% REFERENCIAS
% ============================================================================
\bibliographystyle{apalike}

\begin{thebibliography}{99}

\bibitem[Agirre y Edmonds, 2006]{agirre2006}
Agirre, E., y Edmonds, P. (2006).
\newblock {\em Word Sense Disambiguation: Algorithms and Applications}.
\newblock Springer.

\bibitem[Cañete et al., 2020]{canete2020}
Cañete, J., Chaperon, G., Fuentes, R., Ho, J. H., Kang, H., y Pérez, J. (2020).
\newblock Spanish Pre-Trained BERT Model and Evaluation Data.
\newblock {\em PML4DC at ICLR 2020}.

\bibitem[Garcez et al., 2019]{garcez2019}
Garcez, A. d., Gori, M., Lamb, L. C., Serafini, L., Spranger, M., y Tran, S. N. (2019).
\newblock Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning.
\newblock {\em Journal of Applied Logics}, 6(4), 611-632.

\bibitem[Navigli, 2009]{navigli2009}
Navigli, R. (2009).
\newblock Word Sense Disambiguation: A Survey.
\newblock {\em ACM Computing Surveys}, 41(2), 1-69.

\bibitem[Robinson y Sibert, 1984]{robinson1984}
Robinson, J. A., y Sibert, E. E. (1984).
\newblock LOGLISP: An Alternative to Prolog.
\newblock {\em Machine Intelligence 10}, 399-419.

\bibitem[Takeuchi, 1983]{takeuchi1983}
Takeuchi, I. (1983).
\newblock TAO - A Harmonious Combination of Logic and Objects.
\newblock NTT Electrical Communication Laboratories, Japan.

\bibitem[Warren y Pereira, 1981]{warren1981}
Warren, D. H. D., y Pereira, F. C. N. (1981).
\newblock An Efficient Easily Adaptable System for Interpreting Natural Language Queries.
\newblock {\em DAI Research Paper 155}, University of Edinburgh.

\end{thebibliography}

\end{document}
